# Perspective Cosmology — A Plain-Language Description

**Current as of**: 2026-02-03 (Session ~S212)
**Status**: External communication document
**Audience**: General / non-specialist

**Source files used to build this description**:
- `publications/THESIS.md` (v1.1, central thesis document)
- `THEORY_STRUCTURE.md` (v2.0, complete logical structure)
- `publications/HONEST_ASSESSMENT.md` (balanced evaluation)
- `CLAUDE.md` (project guidelines and claims tiering)

---

## What It Is

Perspective Cosmology is an amateur, speculative theoretical framework — built by a non-professional with AI assistance — that asks one radical question:

**What if the laws of physics aren't arbitrary? What if they're the only mathematically possible outcome of observation itself existing?**

The framework tries to show that if you start from the bare minimum requirements for *anything to be observed at all*, you get forced — step by step — into the exact physics we see: the Standard Model of particle physics, Einstein's general relativity, 3+1 spacetime dimensions, and even specific numerical values of constants like the fine structure constant.

It is **not** established physics. It has not been peer-reviewed. The author openly estimates a 15-30% chance that it's genuinely capturing real physics rather than being an elaborate coincidence. But the results are unusual enough that the author considers them worth investigating.

---

## The Starting Point: What Does Observation Require?

The framework doesn't start with particles, fields, or spacetime. It starts with something more primitive: **what must be true for anything to be distinguishable from anything else?**

Four requirements:

1. **Partiality** — An observer can't see everything. If you could access all of reality at once, there's no "you" separate from reality. There's just... everything. Observation requires a limited viewpoint.

2. **Non-triviality** — An observer must see *something*. A viewpoint that accesses nothing isn't a viewpoint at all.

3. **Distinguishability** — Different things must actually look different. If all states are identical from your viewpoint, there's no information, no observation.

4. **Consistency** — Observations must compose without contradiction. If you observe A, then observe B, then observe A again, the results need to be compatible. You can't get contradictions.

That fourth requirement — consistency — turns out to be enormously constraining.

---

## The Mathematical Bottleneck: Division Algebras

Consistency demands that the algebra governing transitions between observational states has no "zero divisors." In plain terms: no two non-zero observations can combine to give nothing. If you see something real, and I see something real, our combined observation can't cancel to zero.

This is a well-known mathematical constraint. A French mathematician named Frobenius proved in 1877, and Hurwitz extended in 1898, that the *only* number systems satisfying this requirement (over the real numbers, with finite dimensions) are exactly four:

| Number System | Dimension | Everyday Analogy |
|---|---|---|
| **Real numbers** (R) | 1 | The number line |
| **Complex numbers** (C) | 2 | Points on a plane |
| **Quaternions** (H) | 4 | Rotations in 3D space |
| **Octonions** (O) | 8 | An exotic 8-dimensional algebra |

That's it. There are no others. This isn't a choice or an assumption — it's a proven mathematical theorem. The framework claims that these four algebras, with dimensions {1, 2, 4, 8}, are the DNA of physics.

---

## From Algebra to Spacetime

The framework argues:

**Why is spacetime 4-dimensional?** Because time evolution must be *associative* — meaning it doesn't matter how you group sequential events: (A then B) then C must equal A then (B then C). The largest division algebra that's associative is the quaternions, which have 4 dimensions. So spacetime has 4 dimensions (3 space + 1 time).

The octonions (dimension 8) are *not* associative — they break that grouping rule. The framework interprets this as the reason the octonions describe *internal* symmetries (the forces) rather than spacetime.

---

## From Algebra to Forces

The Standard Model of particle physics has three forces, described by the gauge group U(1) x SU(2) x SU(3). These correspond to electromagnetism, the weak nuclear force, and the strong nuclear force. Nobody knows *why* it's these three.

The framework claims it's because each force is the *symmetry group* (automorphism group) of one of the division algebras:

- **Electromagnetism** (U(1)) comes from the symmetries of the **complex numbers**
- **Weak force** (SU(2)) comes from the symmetries of the **quaternions**
- **Strong force** (SU(3)) comes from the symmetries of the **octonions**

The real numbers have no non-trivial symmetries, which is why there's no "fourth force" from them.

This idea — division algebras generating the gauge groups — is not unique to this framework. Several professional physicists (notably Furey, Dixon, and others) have explored this connection. What's distinctive here is pushing it further to derive numerical constants.

---

## The Crystal and Perspectives

The framework introduces two central structures:

**The Crystal**: All of reality viewed as a single, timeless, perfect mathematical object — like a crystalline structure where every dimension is perfectly orthogonal (perpendicular) to every other. Think of it as the "block universe" idea from relativity, but given specific algebraic structure. The Crystal's dimensions are identified with *prime numbers* — each prime is an irreducible, independent direction.

**Perspectives**: Observers are finite viewpoints into the Crystal. A perspective sees only part of the whole, can't reconstruct the whole from what it sees (the access map is non-invertible), and experiences *time* as a sequence of partial views. Time doesn't exist in the Crystal itself — it's an artifact of being a limited observer.

**Crystallization**: The tendency of imperfect structure to become more perfect over time. When dimensions aren't perfectly orthogonal (they have "tilt" or overlap), there's a tendency for that overlap to decrease. This tendency *is* gravity, according to the framework. Gravity isn't a force pulling masses together — it's the mathematical tendency of composite (imperfect) structures to factorize back into primes (perfect orthogonality).

---

## The Prime Number Connection

One of the more unusual aspects: the framework identifies prime numbers with fundamental, irreducible dimensions, and composite numbers with imperfect, overlapping dimensions.

- **Primes** = perfect, orthogonal directions in the Crystal
- **Composites** = imperfect dimensions with residual overlap
- **Gravity** = the process of prime-factorizing composite dimensions back to primes
- **Black holes** = regions where factorization is complete (pure prime space exposed)
- **Mass** = the "cost" of dimensional imperfection

The framework further claims that specific primes show up in physics because they can be written as sums of squares of division algebra dimensions. For example:

- 137 = 4^2 + 11^2 (the fine structure constant's integer part)
- 73 = 3^2 + 8^2 (appears in lepton mass relationships)
- 53 = 2^2 + 7^2 (appears in the strong coupling constant)
- 13 = 2^2 + 3^2 (appears in neutrino mixing angles)

All eight "framework primes" of this form have been found in physical constants, which the author considers significant.

---

## The Numerical Predictions

This is where the framework is most striking and most controversial. Using only the numbers {1, 2, 4, 8} and their algebraic combinations, it produces formulas for fundamental constants:

**The fine structure constant** (which governs the strength of electromagnetism):
- Formula: 1/alpha = 137 + 4/111 = 15211/111
- This gives 137.036036...
- The measured value is 137.035999084
- That's a match to **0.27 parts per million** — using only integers

**The proton-to-electron mass ratio** (why the proton is ~1836 times heavier than the electron):
- Formula: m_p/m_e = 1836 + 11/72
- This gives 1836.15278
- Measured: 1836.15267
- Match to **0.06 parts per million**

**The Weinberg angle** (which determines the relative strengths of electromagnetic and weak forces):
- Formula: cos(theta_W) = 171/194
- Match to **3.75 parts per million**

Beyond these headline results, the framework produces predictions for dozens of other quantities: neutrino mixing angles, quark mixing parameters, the Hubble constant (H_0 = 337/5 = 67.4, which matches the CMB measurement exactly to reported precision), cosmological density parameters, lepton mass ratios, and more.

---

## The Cosmological Picture

The framework extends to cosmology with a cyclic story:

1. **The Crystal exists** — timeless, perfect, all prime dimensions orthogonal
2. **Nucleation** — "cracks" appear, creating imperfect (composite) dimensions. This is the Big Bang.
3. **Expansion** — more composite structure forms, imperfection grows
4. **Peak entropy** — maximum imperfection
5. **Crystallization** — gravity slowly factorizes composites back to primes
   - Black holes do this fast (complete factorization)
   - Normal gravity does it slowly
   - Heat death does it very slowly
6. **Return to Crystal** — all composites eventually factorized back to primes

In this picture, the Hubble tension (the disagreement between different measurements of the universe's expansion rate) is *predicted*, not a problem to solve. The CMB measurement gives H_0 = 337/5 = 67.4, while local measurements give H_0 x 13/12 = 73.0, and the ratio 13/12 has a framework interpretation.

---

## Quantum Mechanics

The framework claims to derive quantum mechanics from the perspective axioms:

- **Hilbert space** emerges because the Crystal has an inner product, and perspectives inherit it
- **Unitary evolution** follows from information conservation during time steps
- **The Schrodinger equation** follows from Stone's theorem applied to unitary evolution
- **The Born rule** (probability = |amplitude|^2) follows from the symmetry of the overlap between perspectives

The *form* of quantum mechanics is derived; the *value* of Planck's constant is not yet derived from the framework.

---

## Dark Matter Prediction

The framework's most testable prediction: dark matter particles should have a mass of about **5.11 GeV** (roughly 5 times the proton mass). Two independent derivation paths give nearly the same number:

- Path 1 (cosmological): m_DM = m_proton x (Omega_DM/Omega_baryon) ~ 5108 MeV
- Path 2 (algebraic): m_DM/m_electron = 10^4, so m_DM ~ 5110 MeV

Experiments like SuperCDMS, LZ, and DarkSide should be able to test this in the 2026-2027 timeframe. If dark matter is found at a different mass, the framework is falsified on this prediction.

---

## What It Gets Right (Potentially)

- Derives the correct gauge groups of the Standard Model from pure algebra
- Produces 3+1 spacetime dimensions from associativity
- Gets 15 fermions per generation from division algebra representation theory
- Produces sub-parts-per-million matches for several fundamental constants using only integers
- Provides a unified picture spanning particle physics, cosmology, CMB, and Big Bang nucleosynthesis from the same handful of numbers

---

## What the Honest Concerns Are

1. **It could be numerology.** With enough algebraic operations on ~30 numbers derived from {1, 2, 4, 8}, you can match many constants to ~1% by chance. The sub-ppm matches are much harder to dismiss, but the percent-level matches are individually weak.

2. **Post-hoc fitting.** The formulas were found *after* the measured values were known. It's very difficult to prove that a formula was *derived* from principles rather than *discovered* by searching and then justified after the fact. The framework is self-aware about this (calling it "the derivation vs. discovery problem").

3. **Amateur work.** The author is not a professional physicist. While this doesn't automatically invalidate the work, it means the derivation chains may have gaps or errors that a trained theorist would catch.

4. **~3 structural assumptions.** Earlier claims of "zero free parameters" have been internally corrected. The framework makes about 3 structural choices (like identifying the scalar field with the complex numbers) that aren't forced by the axioms alone.

5. **The hardest derivation steps are incomplete.** The chain from axioms to specific constant values has gaps, particularly in "Step 5" of the fine structure constant derivation, which remains at the conjecture level.

6. **Internal red team estimate: 15-30% probability of being genuine physics.** The framework's own adversarial analysis gives it less than one-in-three odds.

---

## How It Differs from Other Approaches

- **String theory** introduces extra dimensions and landscapes of solutions. This framework claims to *derive* dimensionality rather than assume it.
- **Loop quantum gravity** quantizes spacetime geometry directly. This framework claims spacetime emerges from algebraic structure.
- **Division algebra approaches** (Furey, Dixon, et al.) explore similar algebraic connections to the Standard Model. This framework pushes further into numerical predictions, which is both its distinction and its risk.

---

## The Bottom Line

Perspective Cosmology is a speculative framework that says: the structure of physics is what you get when you ask "what's the minimum math needed for observation to exist?" It uses four number systems (the division algebras) as its only building blocks and claims to derive an impressively wide range of physics from them.

It has produced some striking numerical coincidences — matching fundamental constants to parts-per-million using simple integer formulas — plus qualitative derivations of the Standard Model's structure. It also has clear falsification criteria, particularly a dark matter mass prediction testable in the near term.

Whether this is a genuine insight into the structure of reality or an elaborate pattern-matching exercise remains genuinely unknown. The author maintains epistemic humility about this, documents failures alongside successes, and explicitly invites skeptical scrutiny. The work is maintained across ~200+ working sessions, ~500+ verification scripts, and detailed self-criticism — which, at minimum, reflects an unusual level of intellectual honesty for a speculative framework.

---

## Claims Summary Table

As of 2026-02-03:

| Tier | Count | Precision | Assessment |
|------|-------|-----------|------------|
| **1** | 12 | < 10 ppm | Individually significant |
| **2** | 16 | 10-10000 ppm | Possibly significant |
| **3** | ~41 | > 100 ppm | Individually weak, collectively notable |
| **Falsified** | 14 | -- | Documented honestly |

---

## Where to Go Next

| Interest | Start Here |
|----------|------------|
| Full technical thesis | `publications/THESIS.md` |
| Honest self-critique | `publications/HONEST_ASSESSMENT.md` |
| Anticipated objections | `publications/OBJECTIONS_AND_RESPONSES.md` |
| Technical overview | `publications/TECHNICAL_SUMMARY.md` |
| Complete theory structure | `THEORY_STRUCTURE.md` |
| Tiered claims | `claims/README.md` |
| Verification scripts | `verification/sympy/` (~514 scripts) |
